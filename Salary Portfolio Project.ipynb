{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Predictions Based on Job Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - DEFINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 1 Define the problem ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the problem in your own words here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import your libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "% matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - DISCOVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 2 Load the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df=pd.read_csv('data/train_features.csv')\n",
    "train_target_df=pd.read.csv('data/train_salaries.csv')\n",
    "test_feature_df=pd.read.csv('data/test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 3 Examine the Data (EDA) ----\n",
    "\n",
    "#Examine first 10 rows in the data frame\n",
    "train_feature_df.head(10)\n",
    "train_target_df.head(10)\n",
    "test_feature_df.head(10)\n",
    "\n",
    "\n",
    "#Check the length and types of the variables\n",
    "train_feature_df.info()\n",
    "train_target_df.info()\n",
    "test_feature_df.info()\n",
    "\n",
    "#Check for Duplicates\n",
    "train_feature_df.duplicated().sum()\n",
    "train_target_df.duplicated().sum()\n",
    "test_feature_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 4 Explore the data (EDA) ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_feature_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6aa3bd900583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Identify numerical and categorical variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_feature_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcategorical_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jobId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'companyId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jobType'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'degree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'major'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'industry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnumeric_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'yearsExperience'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'milesfromMetropolis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_feature_df' is not defined"
     ]
    }
   ],
   "source": [
    "#summarize each feature variable\n",
    "#summarize the target variable\n",
    "#look for correlation between each feature and the target\n",
    "#look for correlation between features\n",
    "\n",
    "#Identify numerical and categorical variables \n",
    "train_feature_df.columns\n",
    "categorical_cols=['jobId', 'companyId', 'jobType', 'degree', 'major', 'industry']\n",
    "numeric_cols=['yearsExperience', 'milesfromMetropolis']\n",
    "\n",
    "#Summarize numerical and categorical variables separately \n",
    "train_feature_df.describe(include=[np.number])\n",
    "train_feature_df.describe(include=['0'])\n",
    "\n",
    "#Merge Independent (feature) and Dependent (target) variables into single dataframe (df)\n",
    "train_df= pd.merge(train_feature_df, train_target_df, on='jobId')\n",
    "train_df.info()\n",
    "train_df.head()\n",
    "\n",
    "#Visualize target variable (salary)\n",
    "plt.figure(figsize= (14,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(train_df.salary)\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(train_df.salary, bins=20)\n",
    "plt.show()\n",
    "\n",
    "#Use IQR to identify potential outliers\n",
    "stat = train_df.salary.describe()\n",
    "print(stat)\n",
    "IQR = stat['75%'] - stat['25%']\n",
    "upper = stat['75%'] + 1.5 * IQR\n",
    "lower = stat['25%'] - 1.5 * IQR\n",
    "print('The upper and lower bounds for suspected outliers are {} and {}.'.format(upper, lower))\n",
    "\n",
    "#Examine Potential Outliers\n",
    "#check potential outlier below lower bound\n",
    "train_df[train_df.salary < 8.5]\n",
    "\n",
    "\n",
    "#check potential outlier above upper bound\n",
    "train_df.loc[train_df.salary > 222.5, 'jobType'].value_counts()\n",
    "\n",
    "# Check most suspicious potential outliers above upper bound\n",
    "train_df[(train_df.salary > 222.5) & (train_df.jobType == 'JUNIOR')]\n",
    "\n",
    "# Remove data with zero salaries\n",
    "train_df = train_df[train_df.salary > 8.5]\n",
    "\n",
    "def plot_feature(df, col):\n",
    "    '''\n",
    "    Make plot for each features\n",
    "    left, the distribution of samples on the feature\n",
    "    right, the dependance of salary on the feature\n",
    "    '''\n",
    "    plt.figure(figsize = (14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if df[col].dtype == 'int64':\n",
    "        df[col].value_counts().sort_index().plot()\n",
    "    else:\n",
    "        #change the categorical variable to category type and order their level by the mean salary\n",
    "        #in each category\n",
    "        mean = df.groupby(col)['salary'].mean()\n",
    "        df[col] = df[col].astype('category')\n",
    "        levels = mean.sort_values().index.tolist()\n",
    "        df[col].cat.reorder_categories(levels, inplace=True)\n",
    "        df[col].value_counts().plot()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Counts')\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    if df[col].dtype == 'int64' or col == 'companyId':\n",
    "        #plot the mean salary for each category and fill between the (mean - std, mean + std)\n",
    "        mean = df.groupby(col)['salary'].mean()\n",
    "        std = df.groupby(col)['salary'].std()\n",
    "        mean.plot()\n",
    "        plt.fill_between(range(len(std.index)), mean.values-std.values, mean.values + std.values, \\\n",
    "                         alpha = 0.1)\n",
    "    else:\n",
    "        sns.boxplot(x = col, y = 'salary', data=df)\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Salaries')\n",
    "    plt.show()\n",
    "    \n",
    "    #Relation between companies and salary\n",
    "    plot_feature(train_df, 'companyId')\n",
    "    \n",
    "    #Relation between job type and salary \n",
    "    plot_feature(train_df, 'jobType')\n",
    "    \n",
    "    #Relation between major and salary\n",
    "    plot_feature(train_df, 'major')\n",
    "    \n",
    "    #Relation between industry and salary\n",
    "    plot_feature(train_df, 'industry')\n",
    "    \n",
    "    #Relation between years of experience and salary\n",
    "    plot_feature(train_df, 'industry')\n",
    "    \n",
    "    #Relation between metropolis distance and salary\n",
    "    plot_feature(train_df, 'milesFromMetropolis')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 5 Establish a baseline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(df, col):\n",
    "    #encode the categories using average salary for each category to replace label\n",
    "    cat_dict ={}\n",
    "    cats = df[col].cat.categories.tolist()\n",
    "    for cat in cats:\n",
    "        cat_dict[cat] = train_df[train_df[col] == cat]['salary'].mean()   \n",
    "    df[col] = df[col].map(cat_dict)\n",
    "\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].dtype.name == \"category\":\n",
    "        encode_label(train_df, col)\n",
    "\n",
    "#Correlations between selected features and response\n",
    "# jobId is discarded because it is unique for individual\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "features = ['companyId', 'jobType', 'degree', 'major', 'industry', 'yearsExperience', 'milesFromMetropolis']\n",
    "sns.heatmap(train_df[features + ['salary']].corr(), cmap='Blues', annot=True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 6 Hypothesize solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brainstorm 3 models that you think may improve results over the baseline model based\n",
    "#on your "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainstorm 3 models that you think may improve results over the baseline model based on your EDA and explain why they're reasonable solutions here.\n",
    "\n",
    "Also write down any new features that you think you should try adding to the model based on your EDA, e.g. interaction variables, summary statistics for each group, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - DEVELOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will cycle through creating features, tuning models, and training/validing models (steps 7-9) until you've reached your efficacy goal\n",
    "\n",
    "#### Your metric will be MSE and your goal is:\n",
    " - <360 for entry-level data science roles\n",
    " - <320 for senior data science roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 7 Engineer features  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that data is ready for modeling\n",
    "#create any new features needed to potentially enhance model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 8 Create models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and tune the models that you brainstormed during part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 9 Test models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do 5-fold cross validation on models and measure MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 10 Select best model  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the model with the lowest error as your \"prodcuction\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 11 Automate pipeline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write script that trains model on entire training set, saves model to disk,\n",
    "#and scores the \"test\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 12 Deploy solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save your prediction to a csv file or optionally save them as a table in a SQL database\n",
    "#additionally, you want to save a visualization and summary of your prediction and feature importances\n",
    "#these visualizations and summaries will be extremely useful to business stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 13 Measure efficacy ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip this step since we don't have the outcomes for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
